{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffcbf25-b383-47d0-9e41-2c3e3d5fdf46",
   "metadata": {},
   "source": [
    "# 1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n",
    "ANSWER:\n",
    "\n",
    "\n",
    "\n",
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two fundamental concepts in probability theory used to describe the probability distribution of a random variable.\n",
    "\n",
    "A Probability Mass Function (PMF) is a function that describes the probability of a discrete random variable taking on a specific value. The PMF maps each possible outcome of a discrete random variable to its probability. It is defined as:\n",
    "\n",
    "P(X=x) = probability that X takes on the value x\n",
    "\n",
    "where X is the random variable, and x is a possible value that X can take on. The sum of all possible outcomes must equal 1. For example, consider rolling a fair six-sided die. The PMF for this random variable would be:\n",
    "\n",
    "P(X=1) = 1/6\n",
    "P(X=2) = 1/6\n",
    "P(X=3) = 1/6\n",
    "P(X=4) = 1/6\n",
    "P(X=5) = 1/6\n",
    "P(X=6) = 1/6\n",
    "\n",
    "where X is the random variable representing the value obtained when rolling the die. Each outcome has an equal probability of 1/6.\n",
    "\n",
    "A Probability Density Function (PDF) is a function that describes the probability of a continuous random variable taking on a specific value within a given range. The PDF maps each possible outcome of a continuous random variable to its probability density. It is defined as:\n",
    "\n",
    "f(x) = probability density at x\n",
    "\n",
    "where x is a continuous variable. The area under the PDF curve must equal 1. For example, consider a normal distribution with mean 0 and standard deviation 1. The PDF for this distribution would be:\n",
    "\n",
    "f(x) = 1/sqrt(2π) * e^(-x^2/2)\n",
    "\n",
    "where x is the continuous variable, and e is the mathematical constant approximately equal to 2.71828. The PDF is bell-shaped, and the area under the curve is equal to 1. The probability of the random variable falling within a certain range is given by the area under the curve between those two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de141d6b-29c9-4a4b-97e5-5859d26012cb",
   "metadata": {},
   "source": [
    "# 2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "ANSWER:\n",
    "\n",
    "\n",
    "\n",
    "A Cumulative Density Function (CDF) is a function that describes the probability that a random variable X takes a value less than or equal to a given value x. In other words, it is the cumulative distribution of the probability of X. The CDF is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "where X is the random variable and x is a specific value. The CDF gives the probability that the value of X is less than or equal to x.\n",
    "\n",
    "For example, consider a random variable X that follows a uniform distribution on the interval [0, 1]. The CDF for this distribution is:\n",
    "\n",
    "F(x) = P(X ≤ x) = x, 0 ≤ x ≤ 1\n",
    "\n",
    "This means that the probability of X being less than or equal to 0.5 is 0.5, and the probability of X being less than or equal to 0.75 is 0.75.\n",
    "\n",
    "The CDF is useful because it provides a way to calculate probabilities for a wide range of distributions. The CDF is often used in statistical analysis, hypothesis testing, and modeling. It is also used to calculate percentiles, which are values that divide a distribution into 100 equal parts. For example, the 50th percentile is the value below which 50% of the observations fall.\n",
    "\n",
    "The CDF is also used to find the inverse of a probability distribution. This is useful for finding values that correspond to a specific probability. For example, if we want to find the value of x such that P(X ≤ x) = 0.25, we can use the inverse of the CDF to find the value of x that corresponds to a probability of 0.25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7205c-aa2c-46bf-8036-a88a412c349d",
   "metadata": {},
   "source": [
    "# 3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "ANSWER:\n",
    "\n",
    "The normal distribution is a widely used probability distribution that arises naturally in many fields, particularly in the sciences, economics, and engineering. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1. Height of individuals in a population\n",
    "2. IQ scores\n",
    "3. Weight of manufactured products\n",
    "4. Errors in measurements\n",
    "5. Exam scores\n",
    "6. Time taken to complete a task\n",
    "7. Blood pressure readings\n",
    "8. Income levels\n",
    "\n",
    "The normal distribution is characterized by two parameters, the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, and the standard deviation represents the spread or variability of the data. The normal distribution is symmetric and bell-shaped, with the mean being located at the center of the curve. The standard deviation controls the width of the curve, with larger standard deviations resulting in wider curves.\n",
    "\n",
    "The parameters of the normal distribution can be used to calculate probabilities of specific events or ranges of events. For example, if we know the mean and standard deviation of a normal distribution, we can calculate the probability of a random observation falling within a certain range of values by using the CDF of the normal distribution. The normal distribution is often used to make predictions and estimate probabilities in situations where the data follows a bell-shaped distribution. It is also used in statistical inference to test hypotheses and estimate confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4d54b-13aa-450c-9dd2-b90f1e44578f",
   "metadata": {},
   "source": [
    "# 4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n",
    "ANSWER:\n",
    "\n",
    "The normal distribution is an important probability distribution in statistics and probability theory. Its importance stems from several key properties:\n",
    "\n",
    "1. Central Limit Theorem: The normal distribution is a limiting case of the sum of a large number of independent, identically distributed random variables. This property is known as the Central Limit Theorem, and it allows the normal distribution to serve as an approximation for many other distributions in real-world applications.\n",
    "\n",
    "2. Ease of Use: The normal distribution is mathematically simple and has well-known properties that make it easy to work with in statistical analysis.\n",
    "\n",
    "3. Universality: The normal distribution is ubiquitous in nature and arises naturally in many fields, including the social sciences, natural sciences, engineering, and economics.\n",
    "\n",
    "Some real-life examples of situations that follow a normal distribution include:\n",
    "\n",
    "1. Heights of adult men and women in a population\n",
    "2. Weights of manufactured products such as cereal boxes or car parts\n",
    "3. IQ scores of a large population\n",
    "4. The number of errors in a large sample of data entry or manufacturing processes\n",
    "5. Test scores in large populations\n",
    "6. Reaction times in a population\n",
    "7. Monthly rainfall in a region over a long period of time\n",
    "\n",
    "In each of these examples, the normal distribution provides a useful model for understanding the data and making predictions. The normal distribution can be used to calculate probabilities, estimate confidence intervals, and test hypotheses in these and many other real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71492db-1195-47c5-a628-f1f7162a47c7",
   "metadata": {},
   "source": [
    "# 5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n",
    "ANSWER:\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single binary experiment, where the outcome is either success or failure. It is named after the Swiss mathematician Jacob Bernoulli, who studied the properties of this distribution in the 17th century. \n",
    "\n",
    "The Bernoulli distribution has a single parameter p, which represents the probability of success in a single trial. The probability mass function (PMF) of a Bernoulli distribution is given by:\n",
    "\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "where X is the random variable that takes on the value 1 for success and 0 for failure.\n",
    "\n",
    "An example of a Bernoulli distribution is the probability of flipping a coin and obtaining heads. If p is the probability of obtaining heads, then the probability of obtaining tails is 1-p.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution models a single binary experiment, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. \n",
    "\n",
    "The Binomial distribution has two parameters, n and p, where n represents the number of trials and p represents the probability of success in a single trial. The probability mass function (PMF) of a Binomial distribution is given by:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is the random variable that takes on values from 0 to n, representing the number of successes in n independent Bernoulli trials.\n",
    "\n",
    "An example of a Binomial distribution is the number of heads obtained when flipping a coin n times. Each individual coin flip is a Bernoulli trial with probability p of obtaining heads, and the number of heads obtained after n trials follows a Binomial distribution with parameters n and p.\n",
    "\n",
    "In summary, the Bernoulli distribution models the outcome of a single binary experiment, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88b5f1-c254-4ae1-b1e3-82755e9222f6",
   "metadata": {},
   "source": [
    "# 6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greaterthan 60? Use the appropriate formula and show your calculations.\n",
    "ANSWER:\n",
    "\n",
    "If we assume that the dataset is normally distributed with a mean of 50 and a standard deviation of 10, we can use the z-score formula to calculate the probability that a randomly selected observation will be greater than 60:\n",
    "\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "where:\n",
    "- x is the value we are interested in (60 in this case)\n",
    "- mu is the population mean (50 in this case)\n",
    "- sigma is the population standard deviation (10 in this case)\n",
    "- z is the z-score representing the number of standard deviations away from the mean\n",
    "\n",
    "Substituting the given values, we get:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "Using a z-table or calculator, we can find the probability that a randomly selected observation will be greater than 60 to be:\n",
    "\n",
    "P(Z > 1) = 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0fcf3-92ca-44b1-bb02-a90b81bb4968",
   "metadata": {},
   "source": [
    "# 7: Explain uniform Distribution with an example.\n",
    "ANSWER:\n",
    "\n",
    "The uniform distribution is a continuous probability distribution that models a situation where all values within a given interval are equally likely to occur. In other words, the probability density function (PDF) is constant within the interval and zero outside of it.\n",
    "\n",
    "An example of a uniform distribution is the probability of obtaining a random number between 0 and 1, where all values in that range are equally likely to occur. The PDF of a uniform distribution with interval [a,b] is given by:\n",
    "\n",
    "f(x) = 1 / (b-a)  for a <= x <= b\n",
    "f(x) = 0  otherwise\n",
    "\n",
    "where x is the random variable, and a and b are the lower and upper bounds of the interval.\n",
    "\n",
    "For instance, suppose we have a lottery system that selects a random number between 0 and 1000. In this case, the probability of any number within the interval [0,1000] is the same, so we can model this situation using a uniform distribution with a = 0 and b = 1000. The PDF of this uniform distribution is:\n",
    "\n",
    "f(x) = 1/1000  for 0 <= x <= 1000\n",
    "f(x) = 0  otherwise\n",
    "\n",
    "This means that any number between 0 and 1000 is equally likely to be selected, and the probability of obtaining any particular number is 1/1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5068858b-4200-4313-ab3e-e17a648d1b30",
   "metadata": {},
   "source": [
    "# 8: What is the z score? State the importance of the z score.\n",
    "ANSWER:\n",
    "\n",
    "The z-score (also known as the standard score) is a measure of the number of standard deviations an observation or data point is away from the mean of its population. It is calculated by subtracting the population mean from the data point and then dividing by the population standard deviation.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "where:\n",
    "- x is the observed value\n",
    "- mu is the population mean\n",
    "- sigma is the population standard deviation\n",
    "\n",
    "The z-score tells us how many standard deviations a data point is away from the mean, and whether it is above or below the mean. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that it is below the mean. A z-score of 0 indicates that the data point is equal to the mean.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize data and make it comparable across different populations or distributions. By converting data to z-scores, we can compare data points from different populations or distributions with different means and standard deviations. Z-scores are also useful in hypothesis testing, as they enable us to determine the probability of observing a data point or sample mean given a certain population mean and standard deviation.\n",
    "\n",
    "In summary, the z-score is an important statistical measure that standardizes data and enables us to compare and analyze data from different populations or distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7af925-262b-4bb6-948d-50601720c289",
   "metadata": {},
   "source": [
    "# 9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "ANSWER:\n",
    "\n",
    "The Central Limit Theorem (CLT) is a fundamental statistical principle that states that as the sample size increases, the sampling distribution of the mean of a random sample from any population approaches a normal distribution, regardless of the shape of the population distribution. In other words, as the sample size becomes larger, the distribution of sample means becomes more and more normal, regardless of the original population distribution.\n",
    "\n",
    "The CLT is significant because it enables us to use the normal distribution to make inferences about the population mean, even when the population distribution is not normal. It is a critical concept in statistics because it allows us to estimate population parameters, such as the mean and standard deviation, based on a sample.\n",
    "\n",
    "The CLT has several implications and applications in statistics, including:\n",
    "\n",
    "1. Sample size determination: The CLT provides guidance on how large a sample size needs to be in order for the sample mean to be a good estimate of the population mean.\n",
    "\n",
    "2. Hypothesis testing: The CLT enables us to use the normal distribution to test hypotheses about population means.\n",
    "\n",
    "3. Confidence intervals: The CLT allows us to construct confidence intervals for the population mean, based on the sample mean and standard deviation.\n",
    "\n",
    "4. Quality control: The CLT is used in quality control to monitor the mean and variability of a process by taking samples and constructing control charts.\n",
    "\n",
    "In summary, the Central Limit Theorem is a critical statistical principle that enables us to make inferences about population means based on sample means, even when the population distribution is not normal. It has broad applications in sample size determination, hypothesis testing, confidence intervals, and quality control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7caf29-e513-4de7-a552-a5e88816f3c0",
   "metadata": {},
   "source": [
    "# 10: State the assumptions of the Central Limit Theorem.\n",
    "ANSWER:\n",
    "\n",
    "The Central Limit Theorem (CLT) relies on several assumptions, which are:\n",
    "\n",
    "1. Random sampling: The samples must be randomly selected from the population, without any bias. This assumption ensures that the sample is representative of the population.\n",
    "\n",
    "2. Independence: Each observation in the sample must be independent of one another. This assumption ensures that each observation contributes equally to the sample mean.\n",
    "\n",
    "3. Finite population: The population must be finite, or the sample size must be less than 10% of the population size. This assumption ensures that the sampling distribution of the mean is not affected by the population size.\n",
    "\n",
    "4. Sample size: The sample size must be sufficiently large. A general rule of thumb is that the sample size should be greater than or equal to 30. However, for populations with high variability, a larger sample size may be needed to ensure that the sampling distribution is approximately normal.\n",
    "\n",
    "5. Population distribution: The population distribution must have a finite mean and standard deviation. If the population is skewed, a larger sample size may be needed to ensure that the sampling distribution is approximately normal.\n",
    "\n",
    "These assumptions are necessary for the CLT to hold and for the sampling distribution of the mean to approach a normal distribution. Violation of these assumptions may result in biased estimates of the population mean and standard deviation. Therefore, it is important to check the validity of these assumptions before using the CLT in any statistical inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
